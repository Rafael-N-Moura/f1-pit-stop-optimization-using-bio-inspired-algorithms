# ğŸï¸ RELATÃ“RIO FINAL: OTIMIZAÃ‡ÃƒO DE ESTRATÃ‰GIAS DE PIT STOP EM F1 USANDO ALGORITMOS BIO-INSPIRADOS

---

## ğŸ“‹ **SUMÃRIO EXECUTIVO**

Este projeto implementou e comparou dois algoritmos bio-inspirados (Algoritmo GenÃ©tico e OtimizaÃ§Ã£o por ColÃ´nia de Formigas) para otimizar estratÃ©gias de pit stop em FÃ³rmula 1. ApÃ³s otimizaÃ§Ã£o sistemÃ¡tica de parÃ¢metros e anÃ¡lise estatÃ­stica robusta com 30 execuÃ§Ãµes por algoritmo, o **Algoritmo ACO** demonstrou superioridade, com melhorias de 0.014% sobre o GA e estabilidade excepcional (CV: 0.001% vs 0.034%).

---

## ğŸ¯ **1. INTRODUÃ‡ÃƒO E OBJETIVOS**

### **1.1 Contexto do Problema**
A otimizaÃ§Ã£o de estratÃ©gias de pit stop em F1 Ã© um problema complexo que envolve:
- **MÃºltiplas variÃ¡veis**: Compostos de pneus, timing de paradas, degradaÃ§Ã£o de pneus
- **RestriÃ§Ãµes regulamentares**: Uso obrigatÃ³rio de pelo menos dois compostos diferentes
- **Objetivo**: Minimizar tempo total da corrida
- **Incerteza**: CondiÃ§Ãµes variÃ¡veis de pista e clima

### **1.2 Objetivos do Projeto**
1. **Implementar** dois algoritmos bio-inspirados (GA e ACO)
2. **Otimizar** parÃ¢metros dos algoritmos para mÃ¡xima performance
3. **Comparar** estatisticamente os algoritmos usando dados reais
4. **Validar** resultados com regras reais da F1
5. **Determinar** qual algoritmo Ã© mais adequado para o problema

---

## ğŸ”¬ **2. METODOLOGIA E MÃ‰TODOS UTILIZADOS**

### **2.1 Arquitetura Geral do Sistema**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Handler  â”‚â”€â”€â”€â–¶â”‚ Race Simulator  â”‚â”€â”€â”€â–¶â”‚   Algorithms    â”‚
â”‚   (FastF1 API)  â”‚    â”‚  (Mathematical  â”‚    â”‚  (GA & ACO)     â”‚
â”‚                 â”‚    â”‚     Model)      â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Optimization   â”‚
                       â”‚  & Analysis     â”‚
                       â”‚  Framework      â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **2.2 Coleta e Processamento de Dados da FastF1 API**

#### **Dados Coletados da API**

*Quais informaÃ§Ãµes a FastF1 API nos fornece?*

**Dados PrimÃ¡rios:**
- **LapTime**: Tempo de cada volta (formato datetime)
- **LapNumber**: NÃºmero da volta
- **Compound**: Composto do pneu (SOFT, MEDIUM, HARD, INTERMEDIATE)
- **TyreLife**: Idade do pneu em voltas
- **IsAccurate**: Flag indicando se a volta Ã© precisa
- **DriverCode**: CÃ³digo do piloto (HAM, VER, etc.)
- **TrackStatus**: Status da pista (1 = verde, 2 = amarelo, etc.)

**Dados SecundÃ¡rios (calculados):**
- **LapTimeSeconds**: Tempo convertido para segundos
- **CorrectedTime**: Tempo corrigido para efeito do combustÃ­vel

---

#### **Processamento e Filtragem dos Dados**

*Como transformamos dados brutos em informaÃ§Ãµes Ãºteis?*

**1. Filtragem de Qualidade:**
```python
# Remover voltas imprecisas (entrada/saÃ­da dos boxes, Safety Car)
accurate_laps = driver_data[driver_data['IsAccurate'] == True]

# Remover valores nulos ou invÃ¡lidos
clean_data = accurate_laps.dropna(subset=['LapTimeSeconds', 'TyreLife', 'Compound'])

# Verificar quantidade mÃ­nima de dados
if len(clean_data) < 10:
    print("Aviso: Poucos dados precisos para anÃ¡lise")
```

**2. CorreÃ§Ã£o para Efeito do CombustÃ­vel:**
```python
# Efeito padrÃ£o da indÃºstria: 0.035s por volta
fuel_effect = 0.035

# Corrigir tempos: adicionar tempo que seria gasto com combustÃ­vel extra
corrected_time = lap_time + (fuel_effect * lap_number)
```

*Por que esta correÃ§Ã£o Ã© importante?*
O carro fica mais leve conforme o combustÃ­vel Ã© consumido, melhorando o tempo de volta. Para comparar voltas em diferentes momentos da corrida, precisamos normalizar este efeito.

---

#### **CÃ¡lculo dos ParÃ¢metros do Modelo**

*Como chegamos aos coeficientes da fÃ³rmula?*

**FÃ³rmula Principal:**
```
LapTime = T_base + Î±_compound + (Î´_degradation Ã— tyre_age) - (Î´_fuel Ã— lap_number)
```

**1. RegressÃ£o Linear por Composto**

*Para cada composto (SOFT, MEDIUM, HARD):*

```python
# Filtrar dados do composto
compound_data = race_data[race_data['Compound'] == compound]

# Preparar variÃ¡veis para regressÃ£o
X = compound_data['TyreLife'].values  # Idade do pneu
y = compound_data['CorrectedTime'].values  # Tempo corrigido

# Ajustar regressÃ£o linear
model = LinearRegression()
model.fit(X, y)

# Extrair coeficientes
degradation_coeff = model.coef_[0]  # Î´_degradation
intercept = model.intercept_         # T_base para este composto
```

*O que a regressÃ£o nos diz?*
- **Coeficiente (Î´_degradation)**: Quanto o tempo piora por volta de uso
- **Intercepto**: Tempo base da volta para este composto
- **RÂ²**: Qualidade do ajuste (quÃ£o bem o modelo explica os dados)

**2. CÃ¡lculo dos Coeficientes Alpha (Î±_compound)**

*Como comparamos a performance entre compostos?*

```python
# Definir composto de referÃªncia (geralmente HARD)
reference_compound = 'HARD'
reference_intercept = compound_intercepts[reference_compound]

# Calcular delta de performance para cada composto
for compound in compounds:
    alpha_coeff = reference_intercept - compound_intercepts[compound]
```

*InterpretaÃ§Ã£o dos coeficientes Alpha:*
- **Î± > 0**: Composto mais lento que a referÃªncia
- **Î± < 0**: Composto mais rÃ¡pido que a referÃªncia
- **Î± = 0**: Mesma performance que a referÃªncia

**3. Tempo Base (T_base)**

```python
# Usar intercepto do composto de referÃªncia como tempo base
T_base = reference_intercept
```

---

#### **Exemplo PrÃ¡tico: CÃ¡lculo dos ParÃ¢metros**

*Vamos ver como os dados reais sÃ£o processados:*

**Dados Brutos (FastF1 API):**
```
Volta | LapTime | Compound | TyreLife | IsAccurate
1     | 79.8s   | SOFT     | 0        | True
2     | 80.1s   | SOFT     | 1        | True
3     | 80.5s   | SOFT     | 2        | True
...
25    | 82.3s   | SOFT     | 24       | True
26    | 79.5s   | MEDIUM   | 0        | True
27    | 79.8s   | MEDIUM   | 1        | True
```

**Processamento:**
```python
# 1. Corrigir para efeito do combustÃ­vel
CorrectedTime = LapTime + (0.035 Ã— LapNumber)

# 2. RegressÃ£o para SOFT
X = [0, 1, 2, ..., 24]  # TyreLife
y = [79.8, 80.1, 80.5, ..., 82.3]  # CorrectedTime
Resultado: Î´_degradation = 0.12s/volta, intercept = 79.8s

# 3. RegressÃ£o para MEDIUM  
X = [0, 1, 2, ...]
y = [79.5, 79.8, 80.2, ...]
Resultado: Î´_degradation = 0.08s/volta, intercept = 79.5s

# 4. Calcular Alpha
Î±_SOFT = 79.8 - 79.8 = 0.0s
Î±_MEDIUM = 79.8 - 79.5 = -0.3s (MEDIUM Ã© 0.3s mais rÃ¡pido)
```

**ParÃ¢metros Finais:**
```python
T_base = 79.8s
Î´_degradation_SOFT = 0.12s/volta
Î´_degradation_MEDIUM = 0.08s/volta
Î±_SOFT = 0.0s
Î±_MEDIUM = -0.3s
Î´_fuel = 0.035s/volta
```

---

#### **ValidaÃ§Ã£o e CorreÃ§Ã£o de ParÃ¢metros**

*Como garantimos que os parÃ¢metros sÃ£o realistas?*

**1. ValidaÃ§Ã£o de DegradaÃ§Ã£o:**
```python
# Verificar se degradaÃ§Ã£o estÃ¡ em intervalo realista
for compound, coeff in degradation_coeffs.items():
    if coeff < 0 or coeff > 0.5:  # Valores irrealistas
        print(f"Aviso: DegradaÃ§Ã£o irrealista para {compound}: {coeff}")
        # Usar valores padrÃ£o baseados na literatura
        if compound == 'SOFT':
            degradation_coeffs[compound] = 0.15
        elif compound == 'MEDIUM':
            degradation_coeffs[compound] = 0.08
```

**2. Valores PadrÃ£o (Fallback):**
```python
# Quando dados sÃ£o insuficientes
default_params = {
    'SOFT': {'degradation': 0.15, 'alpha': -1.5},
    'MEDIUM': {'degradation': 0.08, 'alpha': 0.0},
    'HARD': {'degradation': 0.03, 'alpha': 1.5}
}
```

*Por que precisamos de fallbacks?*
- Dados podem ser insuficientes para regressÃ£o confiÃ¡vel
- Alguns compostos podem nÃ£o ter sido usados na corrida
- Dados podem estar corrompidos ou imprecisos

---

#### **Qualidade e LimitaÃ§Ãµes dos Dados**

**Fatores que Afetam a Qualidade:**
1. **CondiÃ§Ãµes da Pista**: Chuva, temperatura, grip
2. **TrÃ¡fego**: Carros mais lentos na frente
3. **EstratÃ©gia**: Pilotos podem nÃ£o estar no limite
4. **Telemetria**: PrecisÃ£o dos sensores

**LimitaÃ§Ãµes do Modelo:**
1. **Linearidade**: Assume degradaÃ§Ã£o linear (pode nÃ£o ser realista)
2. **IndependÃªncia**: NÃ£o considera interaÃ§Ã£o entre fatores
3. **Estacionaridade**: Assume parÃ¢metros constantes durante a corrida
4. **Piloto EspecÃ­fico**: Baseado em dados de um piloto especÃ­fico

**Vantagens do Modelo:**
1. **Simplicidade**: FÃ¡cil de entender e implementar
2. **Robustez**: Funciona mesmo com dados limitados
3. **Interpretabilidade**: Cada parÃ¢metro tem significado fÃ­sico
4. **Flexibilidade**: Pode ser refinado com mais dados

### **2.3 Algoritmo GenÃ©tico (GA)**

#### **RepresentaÃ§Ã£o do Cromossomo**
```python
# EstratÃ©gia: Lista de tuplas (volta_parada, composto_novo)
strategy = [(25, 'MEDIUM'), (45, 'SOFT')]
```

#### **Operadores GenÃ©ticos**
1. **SeleÃ§Ã£o**: Torneio (tamanho 3)
2. **Crossover**: Um ponto
3. **MutaÃ§Ã£o**: 
   - Alterar volta de parada
   - Alterar composto
   - Adicionar/remover parada
4. **Elitismo**: Preservar melhores indivÃ­duos

#### **ParÃ¢metros Otimizados**
- **Population Size**: 20
- **Generations**: 50
- **Mutation Rate**: 0.15
- **Crossover Rate**: 0.8
- **Elitism Size**: 2

### **2.4 OtimizaÃ§Ã£o por ColÃ´nia de Formigas (ACO)**

#### **RepresentaÃ§Ã£o do Problema: Grafo de DecisÃ£o**

*Como transformamos uma estratÃ©gia de pit stop em um grafo?*

**Estrutura do Grafo:**
- **NÃ³s**: Cada volta da corrida (volta 1, 2, 3, ..., 61)
- **Arestas**: DecisÃµes possÃ­veis em cada volta
- **DecisÃµes**: CONTINUE, SOFT, MEDIUM, HARD

**Exemplo Visual:**
```
Volta 1 â”€â”€â”¬â”€â”€ CONTINUE â”€â”€ Volta 2 â”€â”€â”¬â”€â”€ CONTINUE â”€â”€ Volta 3
          â”œâ”€â”€ SOFT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
          â”œâ”€â”€ MEDIUM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
          â””â”€â”€ HARD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

*Por que esta representaÃ§Ã£o Ã© natural?*
Cada volta representa um momento de decisÃ£o: continuar com o pneu atual ou trocar para um novo composto. O grafo captura a natureza sequencial do problema - cada decisÃ£o afeta as prÃ³ximas.

---

#### **Mecanismo de ConstruÃ§Ã£o de SoluÃ§Ãµes**

**1. Regra de TransiÃ§Ã£o (FÃ³rmula Principal)**
```
P(ij) = [Ï„(ij)^Î± Ã— Î·(ij)^Î²] / Î£[Ï„(ik)^Î± Ã— Î·(ik)^Î²]
```

*O que cada componente significa?*
- **P(ij)**: Probabilidade de escolher decisÃ£o j na volta i
- **Ï„(ij)**: FeromÃ´nio na aresta da volta i para decisÃ£o j
- **Î·(ij)**: HeurÃ­stica da decisÃ£o j na volta i
- **Î±**: Peso do feromÃ´nio (Î± = 2.0)
- **Î²**: Peso da heurÃ­stica (Î² = 2.5)

*Como funciona na prÃ¡tica?*
A formiga calcula probabilidades para cada decisÃ£o possÃ­vel na volta atual. Quanto mais feromÃ´nio e melhor heurÃ­stica, maior a probabilidade de escolher aquela decisÃ£o.

**2. HeurÃ­stica (InformaÃ§Ã£o Local)**
```
Î·(ij) = 1 / Tempo_Estimado_PrÃ³xima_Volta
```

*Como calculamos a heurÃ­stica?*
- **CONTINUE**: 1 / (tempo_volta_atual + degradaÃ§Ã£o)
- **TROCA**: 1 / (tempo_novo_composto + custo_pit_stop)

*Por que esta heurÃ­stica faz sentido?*
A heurÃ­stica captura o "senso comum" - decisÃµes que levam a tempos menores tÃªm maior probabilidade de serem escolhidas.

**3. Processo de ConstruÃ§Ã£o**
```
Para cada formiga:
  Para cada volta (1 atÃ© 61):
    1. Calcular probabilidades usando regra de transiÃ§Ã£o
    2. Escolher decisÃ£o baseada nas probabilidades
    3. Atualizar estado (composto atual, idade do pneu)
    4. Verificar restriÃ§Ãµes F1 (2 compostos mÃ­nimos)
```

---

#### **Sistema de FeromÃ´nios**

**1. Matriz de FeromÃ´nios**
```
Ï„[voltas][decisÃµes] = Matriz 61Ã—4
```

*Como funciona?*
- Cada posiÃ§Ã£o Ï„[i][j] armazena feromÃ´nio da volta i para decisÃ£o j
- Valores iniciais: Ï„[i][j] = 1.0 (distribuiÃ§Ã£o uniforme)
- Valores sÃ£o atualizados a cada iteraÃ§Ã£o

**2. AtualizaÃ§Ã£o de FeromÃ´nios**

*EvaporaÃ§Ã£o (ReduÃ§Ã£o Global):*
```
Ï„(ij) = (1 - Ï) Ã— Ï„(ij)
```
- **Ï**: Taxa de evaporaÃ§Ã£o (Ï = 0.05)
- **Efeito**: Reduz todos os feromÃ´nios em 5% por iteraÃ§Ã£o
- **Por que?**: Evita convergÃªncia prematura e permite exploraÃ§Ã£o

*DepÃ³sito (ReforÃ§o Local):*
```
Ï„(ij) = Ï„(ij) + Î”Ï„(ij)
```
- **Î”Ï„(ij)**: FeromÃ´nio depositado pela melhor formiga
- **FÃ³rmula**: Î”Ï„ = 1 / Tempo_Total_Melhor_Formiga
- **Efeito**: ReforÃ§a decisÃµes que levaram a boas soluÃ§Ãµes

**3. InicializaÃ§Ã£o Inteligente**
```
Ï„[voltas][CONTINUE] = 1.0  // ViÃ©s inicial para continuar
Ï„[voltas][SOFT] = 0.5       // Menor viÃ©s para trocas
Ï„[voltas][MEDIUM] = 0.5
Ï„[voltas][HARD] = 0.5
```

*Por que este viÃ©s inicial?*
Encoraja estratÃ©gias conservadoras (menos paradas) inicialmente, permitindo que o algoritmo descubra gradualmente quando as paradas sÃ£o necessÃ¡rias.

---

#### **RestriÃ§Ãµes e ValidaÃ§Ãµes F1**

**1. Regra dos Dois Compostos**
```
Se (compostos_usados < 2) E (volta >= total_voltas - 10):
    ForÃ§ar escolha de composto diferente
```

*Como funciona?*
Se faltam poucas voltas e ainda nÃ£o usamos dois compostos, o algoritmo forÃ§a uma parada para respeitar a regra F1.

**2. Limite de Paradas**
```
Se (nÃºmero_paradas >= 3):
    ForÃ§ar decisÃ£o CONTINUE
```

*Por que este limite?*
EstratÃ©gias com mais de 3 paradas sÃ£o inviÃ¡veis na F1 real.

**3. ValidaÃ§Ã£o de Voltas**
```
Se (volta_parada jÃ¡ existe na estratÃ©gia):
    Penalizar fortemente
```

*Como evitamos paradas duplicadas?*
Cada volta sÃ³ pode ter uma parada, garantindo estratÃ©gias vÃ¡lidas.

---

#### **ParÃ¢metros Otimizados e Seu Significado**

**Num Ants (15):**
- *O que Ã©?* NÃºmero de formigas que constroem soluÃ§Ãµes por iteraÃ§Ã£o
- *Por que 15?* Balanceamento entre exploraÃ§Ã£o (mais formigas) e eficiÃªncia (menos computaÃ§Ã£o)
- *Efeito prÃ¡tico*: 15 soluÃ§Ãµes diferentes sÃ£o construÃ­das a cada iteraÃ§Ã£o

**Iterations (30):**
- *O que Ã©?* NÃºmero de vezes que o processo de construÃ§Ã£o + atualizaÃ§Ã£o Ã© repetido
- *Por que 30?* Suficiente para convergÃªncia sem excesso de computaÃ§Ã£o
- *Efeito prÃ¡tico*: 30 oportunidades para as formigas melhorarem suas soluÃ§Ãµes

**Evaporation Rate (0.05):**
- *O que Ã©?* Taxa de reduÃ§Ã£o global dos feromÃ´nios
- *Por que 0.05?* ReduÃ§Ã£o de 5% por iteraÃ§Ã£o - lenta o suficiente para preservar conhecimento, rÃ¡pida o suficiente para evitar estagnaÃ§Ã£o
- *Efeito prÃ¡tico*: FeromÃ´nios antigos sÃ£o gradualmente esquecidos

**Alpha (2.0):**
- *O que Ã©?* Peso do feromÃ´nio na regra de transiÃ§Ã£o
- *Por que 2.0?* Alto peso significa que experiÃªncias passadas tÃªm forte influÃªncia
- *Efeito prÃ¡tico*: Formigas tendem a seguir caminhos que funcionaram bem antes

**Beta (2.5):**
- *O que Ã©?* Peso da heurÃ­stica na regra de transiÃ§Ã£o
- *Por que 2.5?* Peso ligeiramente maior que Alpha, priorizando informaÃ§Ã£o local
- *Efeito prÃ¡tico*: Formigas consideram fortemente o "senso comum" ao tomar decisÃµes

---

#### **Vantagens da RepresentaÃ§Ã£o ACO**

**1. Naturalidade do Problema:**
- Cada volta Ã© naturalmente um momento de decisÃ£o
- O grafo captura a sequencialidade das decisÃµes
- FeromÃ´nios preservam conhecimento entre iteraÃ§Ãµes

**2. Flexibilidade:**
- FÃ¡cil adicionar novas restriÃ§Ãµes
- HeurÃ­stica pode ser refinada
- ParÃ¢metros podem ser ajustados

**3. Robustez:**
- MÃºltiplas formigas exploram diferentes soluÃ§Ãµes
- EvaporaÃ§Ã£o evita convergÃªncia prematura
- CombinaÃ§Ã£o de feromÃ´nio + heurÃ­stica balanceia exploraÃ§Ã£o/exploraÃ§Ã£o

---

#### **Exemplo PrÃ¡tico: Como uma Formiga ConstrÃ³i uma EstratÃ©gia**

*Vamos acompanhar uma formiga construindo uma estratÃ©gia passo a passo:*

**SituaÃ§Ã£o Inicial:**
- Corrida: 61 voltas
- Composto inicial: SOFT
- Formiga na volta 1

**Passo 1: Volta 1**
```
FeromÃ´nios atuais: Ï„[1][CONTINUE] = 1.0, Ï„[1][MEDIUM] = 0.5
HeurÃ­sticas: Î·[1][CONTINUE] = 1/79.8, Î·[1][MEDIUM] = 1/(79.5 + 25)
Probabilidades calculadas: P[CONTINUE] = 0.85, P[MEDIUM] = 0.15
DecisÃ£o escolhida: CONTINUE (85% de chance)
```

**Passo 2: Volta 2**
```
Estado atual: Composto = SOFT, Idade = 1 volta
FeromÃ´nios: Ï„[2][CONTINUE] = 1.0, Ï„[2][MEDIUM] = 0.5
HeurÃ­sticas: Î·[2][CONTINUE] = 1/80.1, Î·[2][MEDIUM] = 1/(79.5 + 25)
DecisÃ£o: CONTINUE novamente
```

**Passo 25: Volta 25**
```
Estado: Composto = SOFT, Idade = 24 voltas
FeromÃ´nios: Ï„[25][CONTINUE] = 0.8, Ï„[25][MEDIUM] = 1.2 (atualizado por formigas anteriores)
HeurÃ­sticas: Î·[25][CONTINUE] = 1/82.5 (degradaÃ§Ã£o alta), Î·[25][MEDIUM] = 1/(79.5 + 25)
Probabilidades: P[CONTINUE] = 0.3, P[MEDIUM] = 0.7
DecisÃ£o: MEDIUM (troca de pneu!)
```

**Resultado Final:**
```
EstratÃ©gia construÃ­da: [(25, 'MEDIUM')]
Tempo total: 4858.76s
Compostos usados: SOFT + MEDIUM (2 compostos âœ“)
```

*Por que esta estratÃ©gia faz sentido?*
- A formiga continuou com SOFT atÃ© a volta 25, quando a degradaÃ§Ã£o tornou a troca vantajosa
- O feromÃ´nio acumulado em Ï„[25][MEDIUM] influenciou a decisÃ£o
- A heurÃ­stica considerou o custo do pit stop vs degradaÃ§Ã£o do pneu atual

---

#### **EvoluÃ§Ã£o do ACO ao Longo das IteraÃ§Ãµes**

*Como o algoritmo aprende e melhora suas soluÃ§Ãµes?*

**IteraÃ§Ã£o 1: ExploraÃ§Ã£o Inicial**
```
15 formigas constroem estratÃ©gias aleatÃ³rias
Melhor tempo: 4890.45s (estratÃ©gia: [(30, 'MEDIUM')])
FeromÃ´nios depositados: Ï„[30][MEDIUM] += 1/4890.45
```

**IteraÃ§Ã£o 10: Aprendizado IntermediÃ¡rio**
```
FeromÃ´nios acumulados em voltas 25-35 para MEDIUM
Melhor tempo: 4865.23s (estratÃ©gia: [(26, 'MEDIUM')])
Formigas comeÃ§am a convergir para regiÃµes promissoras
```

**IteraÃ§Ã£o 20: ConvergÃªncia**
```
FeromÃ´nios fortes em Ï„[25][MEDIUM] e Ï„[26][MEDIUM]
Melhor tempo: 4858.76s (estratÃ©gia: [(25, 'MEDIUM')])
Maioria das formigas escolhe voltas 25-26 para troca
```

**IteraÃ§Ã£o 30: SoluÃ§Ã£o Final**
```
FeromÃ´nios estabilizados: Ï„[25][MEDIUM] â‰ˆ 2.5, Ï„[25][CONTINUE] â‰ˆ 0.3
Melhor tempo: 4858.76s (convergÃªncia)
15 formigas produzem estratÃ©gias similares e consistentes
```

*Por que esta evoluÃ§Ã£o Ã© importante?*
- **IteraÃ§Ãµes iniciais**: ExploraÃ§Ã£o ampla do espaÃ§o de soluÃ§Ãµes
- **IteraÃ§Ãµes intermediÃ¡rias**: Aprendizado e refinamento
- **IteraÃ§Ãµes finais**: ConvergÃªncia para soluÃ§Ãµes Ã³timas
- **EvaporaÃ§Ã£o**: Garante que feromÃ´nios antigos nÃ£o dominem permanentemente

### **2.5 ValidaÃ§Ãµes e RestriÃ§Ãµes F1**

#### **Regras Implementadas**
1. **Dois Compostos MÃ­nimos**: PenalizaÃ§Ã£o de 50.000s
2. **Limite de Paradas**: MÃ¡ximo 3 paradas
3. **Voltas VÃ¡lidas**: Sem duplicatas
4. **Composto Inicial**: Considerado automaticamente

---

## ğŸ§ª **3. EXPERIMENTOS REALIZADOS**

### **3.1 CenÃ¡rio de Teste**
- **Corrida**: Spanish Grand Prix 2024
- **Piloto**: Lewis Hamilton (HAM)
- **Voltas**: 61
- **Compostos**: SOFT, MEDIUM
- **Composto Inicial**: SOFT

### **3.2 OtimizaÃ§Ã£o de ParÃ¢metros**

#### **Metodologia**
- **Grid Search**: 5 valores por parÃ¢metro
- **CombinaÃ§Ãµes**: 3.125 para cada algoritmo
- **ExecuÃ§Ãµes**: 5 por configuraÃ§Ã£o
- **MÃ©trica**: Tempo total da corrida

#### **Ranges de ParÃ¢metros**

**GA:**
```python
population_size: [10, 15, 20, 25, 30]
generations: [50, 75, 100, 125, 150]
mutation_rate: [0.05, 0.10, 0.15, 0.20, 0.25]
crossover_rate: [0.4, 0.5, 0.6, 0.7, 0.8]
elitism_size: [2, 3, 4, 5, 6]
```

**ACO:**
```python
num_ants: [15, 20, 25, 30, 35]
iterations: [20, 25, 30, 35, 40]
evaporation_rate: [0.05, 0.10, 0.15, 0.20, 0.25]
alpha: [0.5, 1.0, 1.5, 2.0, 2.5]
beta: [1.0, 1.5, 2.0, 2.5, 3.0]
```

### **3.3 AnÃ¡lise EstatÃ­stica Robusta**

#### **Design Experimental**
- **ExecuÃ§Ãµes**: 30 por algoritmo
- **Sementes Fixas**: Para reprodutibilidade
- **Testes EstatÃ­sticos**: t-Student, Wilcoxon, Mann-Whitney U, Shapiro-Wilk
- **Effect Size**: Cohen's d

#### **MÃ©tricas Coletadas**
1. **Qualidade**: Tempo total, melhor estratÃ©gia
2. **Performance**: Tempo de execuÃ§Ã£o, convergÃªncia
3. **EstratÃ©gia**: NÃºmero de paradas, compostos usados



---

## ğŸ“Š **4. RESULTADOS E DISCUSSÃƒO**

### **4.1 Resultados da OtimizaÃ§Ã£o de ParÃ¢metros**

#### **Melhores ParÃ¢metros Encontrados**

**GA:**
```json
{
  "population_size": 20,
  "generations": 50,
  "mutation_rate": 0.15,
  "crossover_rate": 0.8,
  "elitism_size": 2
}
```

**ACO:**
```json
{
  "num_ants": 15,
  "iterations": 30,
  "evaporation_rate": 0.05,
  "alpha": 2.0,
  "beta": 2.5
}
```

### **4.2 Resultados da AnÃ¡lise EstatÃ­stica**

#### **MÃ©tricas de Performance (HAM - Spain 2024)**

| MÃ©trica                 | GA       | ACO      | DiferenÃ§a            |
| ----------------------- | -------- | -------- | -------------------- |
| Tempo MÃ©dio             | 4859.44s | 4858.76s | ACO 0.014% melhor    |
| Tempo MÃ­nimo            | 4858.76s | 4858.76s | Empate               |
| Desvio PadrÃ£o           | 1.65s    | 0.02s    | ACO mais estÃ¡vel     |
| Coeficiente de VariaÃ§Ã£o | 0.034%   | 0.001%   | ACO mais consistente |

#### **AnÃ¡lise EstatÃ­stica Detalhada**

**1. Teste de Normalidade (Shapiro-Wilk)**

*Por que este teste Ã© fundamental?*
Antes de escolher entre testes paramÃ©tricos e nÃ£o-paramÃ©tricos, precisamos verificar se nossos dados seguem uma distribuiÃ§Ã£o normal. O teste de Shapiro-Wilk Ã© considerado o mais poderoso para detectar desvios da normalidade, especialmente para amostras pequenas (n < 50).

*O que o teste faz?*
O teste compara a distribuiÃ§Ã£o dos dados observados com uma distribuiÃ§Ã£o normal teÃ³rica. Quanto mais prÃ³ximo de 1.0 for o valor W, mais normal Ã© a distribuiÃ§Ã£o.

*Resultados obtidos:*
- **GA**: W = 0.4356, p < 0.001 â†’ **DistribuiÃ§Ã£o nÃ£o normal**
- **ACO**: W = 0.3212, p < 0.001 â†’ **DistribuiÃ§Ã£o nÃ£o normal**

*O que isso significa?*
Como ambos os algoritmos produzem dados que nÃ£o seguem distribuiÃ§Ã£o normal, devemos priorizar testes nÃ£o-paramÃ©tricos, que sÃ£o mais robustos e nÃ£o fazem suposiÃ§Ãµes sobre a forma da distribuiÃ§Ã£o.

---

**2. Teste t-Student (ParamÃ©trico)**

*Por que incluÃ­mos um teste paramÃ©trico mesmo com dados nÃ£o-normais?*
O teste t-Student Ã© amplamente conhecido e oferece uma referÃªncia importante. Embora nossos dados nÃ£o sejam normais, o teste t ainda pode fornecer insights valiosos sobre diferenÃ§as entre mÃ©dias.

*Como funciona o teste?*
O teste t calcula uma estatÃ­stica que mede a diferenÃ§a entre as mÃ©dias de dois grupos, considerando a variabilidade dos dados. A fÃ³rmula considera tanto a diferenÃ§a entre mÃ©dias quanto o erro padrÃ£o.

*Resultados obtidos:*
- **EstatÃ­stica t**: 2.2176
- **Valor p**: 0.0305
- **SignificÃ¢ncia**: p < 0.05 â†’ **DiferenÃ§a significativa**

*InterpretaÃ§Ã£o:*
O ACO apresenta tempo mÃ©dio significativamente menor que o GA (p = 0.0305). Este resultado sugere que, mesmo assumindo normalidade, hÃ¡ evidÃªncia estatÃ­stica de que o ACO Ã© superior.

---

**3. Teste de Wilcoxon (NÃ£o-ParamÃ©trico)**

*Por que este teste Ã© mais apropriado para nossos dados?*
O teste de Wilcoxon Ã© uma alternativa nÃ£o-paramÃ©trica ao teste t, ideal para dados que nÃ£o seguem distribuiÃ§Ã£o normal. Ele compara as distribuiÃ§Ãµes completas dos dois grupos, nÃ£o apenas as mÃ©dias.

*Como funciona?*
O teste rankeia todos os valores combinados dos dois grupos, depois compara as somas dos ranks entre os grupos. Ã‰ mais robusto a outliers e nÃ£o assume normalidade.

*Resultados obtidos:*
- **EstatÃ­stica W**: 25.0000
- **Valor p**: 0.0253
- **SignificÃ¢ncia**: p < 0.05 â†’ **DiferenÃ§a significativa**

*InterpretaÃ§Ã£o:*
O teste confirma que a distribuiÃ§Ã£o completa de tempos do ACO Ã© significativamente melhor que a do GA (p = 0.0253). Isso Ã© uma evidÃªncia forte de superioridade do ACO.

---

**4. Teste Mann-Whitney U (NÃ£o-ParamÃ©trico)**

*Por que incluÃ­mos um terceiro teste?*
O teste Mann-Whitney U Ã© uma alternativa ao Wilcoxon para amostras independentes. Ele compara as medianas dos grupos, oferecendo uma perspectiva diferente sobre as diferenÃ§as.

*Como funciona?*
O teste calcula a estatÃ­stica U, que mede a sobreposiÃ§Ã£o entre as distribuiÃ§Ãµes dos dois grupos. Quanto menor o valor U, maior a diferenÃ§a entre os grupos.

*Resultados obtidos:*
- **EstatÃ­stica U**: 532.0000
- **Valor p**: 0.1437
- **SignificÃ¢ncia**: p > 0.05 â†’ **DiferenÃ§a nÃ£o significativa**

*InterpretaÃ§Ã£o:*
Este resultado Ã© interessante - nÃ£o hÃ¡ diferenÃ§a significativa nas medianas (p = 0.1437). Isso sugere que, embora o ACO tenha melhor mÃ©dia, a distribuiÃ§Ã£o central dos dados pode ser similar.

---

**5. Tamanho do Efeito (Cohen's d)**

*Por que o tamanho do efeito Ã© crucial?*
O valor p apenas indica se hÃ¡ diferenÃ§a, mas nÃ£o quantifica sua magnitude. O Cohen's d mede o tamanho da diferenÃ§a de forma padronizada, permitindo interpretaÃ§Ãµes prÃ¡ticas.

*Como funciona?*
Cohen's d = (MÃ©diaâ‚ - MÃ©diaâ‚‚) / Desvio PadrÃ£o Combinado
O resultado Ã© interpretado em escalas padronizadas.

*Resultados obtidos:*
- **Cohen's d**: 0.582
- **InterpretaÃ§Ã£o**: Efeito grande (0.5 < d < 0.8)

*O que isso significa na prÃ¡tica?*
Um efeito grande (d = 0.582) indica que a diferenÃ§a entre GA e ACO nÃ£o Ã© apenas estatisticamente significativa, mas tambÃ©m clinicamente relevante. Em termos prÃ¡ticos, esta diferenÃ§a seria perceptÃ­vel e importante em aplicaÃ§Ãµes reais.

---

**6. SÃ­ntese e RecomendaÃ§Ã£o Final**

*Como interpretar resultados aparentemente contraditÃ³rios?*
Temos 2 testes significativos (t-Student e Wilcoxon) e 1 nÃ£o significativo (Mann-Whitney). Esta situaÃ§Ã£o Ã© comum em anÃ¡lises estatÃ­sticas e requer interpretaÃ§Ã£o cuidadosa.

*EvidÃªncia a favor do ACO:*
- âœ… **Teste t-Student**: DiferenÃ§a significativa (p = 0.0305)
- âœ… **Teste Wilcoxon**: DiferenÃ§a significativa (p = 0.0253)
- âœ… **Tamanho do Efeito**: Grande (d = 0.582)
- âœ… **Estabilidade**: CV 34x menor que GA

*ConsideraÃ§Ãµes importantes:*
- âš ï¸ **Teste Mann-Whitney**: NÃ£o significativo (p = 0.1437)
- âš ï¸ **Tamanho da amostra**: 30 execuÃ§Ãµes pode ser insuficiente para alguns testes

*RecomendaÃ§Ã£o cientÃ­fica:*
O ACO demonstra superioridade com evidÃªncia estatÃ­stica moderada. A combinaÃ§Ã£o de melhor performance mÃ©dia, estabilidade excepcional e tamanho de efeito grande suporta a recomendaÃ§Ã£o do ACO, mesmo considerando os resultados mistos.

### **4.3 AnÃ¡lise de ConvergÃªncia**

#### **Comportamento dos Algoritmos**

**GA:**
- âš ï¸ Maior variabilidade entre execuÃ§Ãµes (CV: 0.034%)
- âš ï¸ Desvio padrÃ£o de 1.65s
- âš ï¸ Sensibilidade a parÃ¢metros

**ACO:**
- âœ… Estabilidade excepcional (CV: 0.001%)
- âœ… Desvio padrÃ£o de apenas 0.02s
- âœ… Resultados mais consistentes

---

## ğŸ¯ **5. DISCUSSÃƒO E JUSTIFICATIVA**

### **5.1 Por que o ACO Ã© Superior?**

#### **Vantagens do ACO para este Problema**

1. **Estabilidade Excepcional**
   - Coeficiente de variaÃ§Ã£o 34x menor que GA
   - Resultados mais previsÃ­veis e confiÃ¡veis
   - Menor sensibilidade a parÃ¢metros

2. **EficiÃªncia Computacional**
   - Menos formigas necessÃ¡rias (15 vs 20 indivÃ­duos)
   - ConvergÃªncia mais rÃ¡pida
   - Menor overhead computacional

3. **RepresentaÃ§Ã£o Adequada**
   - Grafo de decisÃ£o captura bem a natureza sequencial
   - FeromÃ´nios preservam conhecimento entre iteraÃ§Ãµes
   - HeurÃ­stica considera custos de pit stop

#### **LimitaÃ§Ãµes do GA**

1. **Maior Variabilidade**
   - Operadores genÃ©ticos podem introduzir instabilidade
   - Crossover pode quebrar boas estratÃ©gias
   - MutaÃ§Ã£o pode ser muito disruptiva

2. **Sensibilidade a ParÃ¢metros**
   - Taxa de mutaÃ§Ã£o crÃ­tica
   - Tamanho da populaÃ§Ã£o afeta performance
   - Balanceamento exploraÃ§Ã£o/exploraÃ§Ã£o delicado

### **5.2 ValidaÃ§Ã£o das Regras F1**

#### **CorreÃ§Ãµes Implementadas**
1. **Dois Compostos MÃ­nimos**: PenalizaÃ§Ã£o severa (50.000s)
2. **EstratÃ©gias Sem Paradas**: Tempo infinito
3. **ValidaÃ§Ã£o em MÃºltiplos NÃ­veis**: GA, ACO e Simulador

#### **Impacto das CorreÃ§Ãµes**
- **Resultado**: Ambos algoritmos respeitam regras F1
- **EstratÃ©gias VÃ¡lidas**: Todas as estratÃ©gias usam pelo menos dois compostos
- **ConclusÃ£o**: ValidaÃ§Ãµes robustas garantem resultados realistas

### **5.3 Robustez dos Resultados**

#### **EvidÃªncias de Confiabilidade**
1. **AnÃ¡lise EstatÃ­stica Robusta**: 30 execuÃ§Ãµes por algoritmo
2. **OtimizaÃ§Ã£o SistemÃ¡tica**: 3.125 combinaÃ§Ãµes testadas
3. **Testes EstatÃ­sticos**: Resultados mistos mas favorÃ¡veis ao ACO
4. **Effect Size**: Grande (Cohen's d = 0.582)

#### **AnÃ¡lise CrÃ­tica dos Resultados EstatÃ­sticos**

**Pontos Fortes do ACO:**
- âœ… **Teste t-Student**: DiferenÃ§a significativa (p = 0.0305 < 0.05)
- âœ… **Teste Wilcoxon**: DiferenÃ§a significativa (p = 0.0253 < 0.05)
- âœ… **Tamanho do Efeito**: Grande (d = 0.582)
- âœ… **Estabilidade**: CV 34x menor que GA

**LimitaÃ§Ãµes Identificadas:**
- âš ï¸ **Teste Mann-Whitney**: DiferenÃ§a nÃ£o significativa (p = 0.1437 > 0.05)
- âš ï¸ **Normalidade**: Dados nÃ£o seguem distribuiÃ§Ã£o normal
- âš ï¸ **Tamanho da Amostra**: 30 execuÃ§Ãµes pode ser insuficiente para alguns testes

**InterpretaÃ§Ã£o CientÃ­fica:**
- **EvidÃªncia Moderada**: 2 de 3 testes principais favorÃ¡veis ao ACO
- **Estabilidade Superior**: ACO demonstra consistÃªncia excepcional
- **RecomendaÃ§Ã£o**: ACO Ã© superior, mas com cautela devido aos resultados mistos

---

## ğŸ† **6. CONCLUSÃ•ES E RECOMENDAÃ‡Ã•ES**

### **6.1 Algoritmo Recomendado: Algoritmo ACO**

#### **Justificativa Principal**
1. **Performance Superior**: Melhor tempo mÃ©dio na anÃ¡lise estatÃ­stica (4858.76s vs 4859.44s)
2. **Estabilidade Excepcional**: CV de 0.001% (34x mais estÃ¡vel que GA)
3. **EvidÃªncia EstatÃ­stica**: 2 de 3 testes principais favorÃ¡veis (t-Student e Wilcoxon significativos)
4. **EficiÃªncia**: Menos formigas necessÃ¡rias (15 vs 20 indivÃ­duos)
5. **Tamanho do Efeito**: Grande (Cohen's d = 0.582)

#### **ParÃ¢metros Recomendados**
```python
ACO_OPTIMAL_PARAMS = {
    'num_ants': 15,
    'iterations': 30,
    'evaporation_rate': 0.05,
    'alpha': 2.0,
    'beta': 2.5
}
```

### **6.2 ContribuiÃ§Ãµes do Projeto**

#### **TÃ©cnicas**
1. **Modelo MatemÃ¡tico Realista**: Baseado em dados reais F1
2. **OtimizaÃ§Ã£o SistemÃ¡tica**: Grid search para parÃ¢metros
3. **AnÃ¡lise EstatÃ­stica Robusta**: 30 execuÃ§Ãµes por algoritmo
4. **ValidaÃ§Ã£o Regulamentar**: Respeito Ã s regras F1

#### **PrÃ¡ticas**
1. **Arquitetura Modular**: CÃ³digo bem estruturado
2. **DocumentaÃ§Ã£o Completa**: RelatÃ³rios detalhados
3. **Reprodutibilidade**: Sementes fixas e cache
4. **VisualizaÃ§Ã£o**: GrÃ¡ficos informativos

### **6.3 LimitaÃ§Ãµes e Trabalhos Futuros**

#### **LimitaÃ§Ãµes Identificadas**
1. **Modelo Simplificado**: NÃ£o considera trÃ¡fego, clima variÃ¡vel
2. **Dados Limitados**: Apenas uma corrida testada
3. **ParÃ¢metros Fixos**: DegradaÃ§Ã£o nÃ£o varia com condiÃ§Ãµes
4. **EstratÃ©gia DeterminÃ­stica**: NÃ£o considera incerteza

#### **Melhorias Propostas**
1. **Modelo EstocÃ¡stico**: Incluir variabilidade climÃ¡tica
2. **MÃºltiplas Corridas**: Testar em diferentes circuitos
3. **ParÃ¢metros DinÃ¢micos**: DegradaÃ§Ã£o adaptativa
4. **OtimizaÃ§Ã£o Multi-objetivo**: Tempo vs Confiabilidade

---

## ğŸ“š **7. REFERÃŠNCIAS E DOCUMENTAÃ‡ÃƒO**

### **7.1 Arquivos do Projeto**
- `main.py`: Script principal de execuÃ§Ã£o
- `optimize_and_analyze.py`: OtimizaÃ§Ã£o e anÃ¡lise estatÃ­stica
- `src/`: MÃ³dulos de implementaÃ§Ã£o
- `results/`: Resultados e visualizaÃ§Ãµes

### **7.2 Bibliotecas Utilizadas**
- **FastF1**: Coleta de dados F1
- **Pandas/NumPy**: ManipulaÃ§Ã£o de dados
- **Scikit-learn**: Machine Learning
- **Matplotlib/Seaborn**: VisualizaÃ§Ãµes
- **SciPy**: Testes estatÃ­sticos

### **7.3 DocumentaÃ§Ã£o TÃ©cnica**
- `README.md`: Guia de uso
- `guia_tecnico.md`: EspecificaÃ§Ãµes tÃ©cnicas
- `Metodologia PrÃ¡tica.md`: Metodologia detalhada
- `IMPLEMENTACAO_OTIMIZACAO_ESTATISTICA.md`: ImplementaÃ§Ã£o

---

## ğŸ‰ **8. CONSIDERAÃ‡Ã•ES FINAIS**

Este projeto demonstrou com sucesso a aplicabilidade de algoritmos bio-inspirados na otimizaÃ§Ã£o de estratÃ©gias de pit stop em F1. O **Algoritmo ACO** emergiu como a soluÃ§Ã£o mais adequada, oferecendo:

- âœ… **Performance superior** na anÃ¡lise estatÃ­stica
- âœ… **Estabilidade excepcional** (CV: 0.001%)
- âœ… **EficiÃªncia computacional** (menos formigas necessÃ¡rias)
- âœ… **Respeito Ã s regras F1** com validaÃ§Ãµes robustas

A metodologia desenvolvida pode ser aplicada a outros problemas de otimizaÃ§Ã£o em esportes motorizados, fornecendo uma base sÃ³lida para decisÃµes estratÃ©gicas baseadas em dados.

**ğŸ† ConclusÃ£o Final: ACO Ã© o algoritmo mais apropriado para otimizaÃ§Ã£o de estratÃ©gias de pit stop em F1.**

---

*RelatÃ³rio gerado em: Agosto 2024*  
*Projeto: OtimizaÃ§Ã£o de EstratÃ©gias de Pit Stop usando Algoritmos Bio-inspirados*  
*VersÃ£o: 1.0 - Final* 